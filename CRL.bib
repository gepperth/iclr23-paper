@inproceedings{Xu2018,
  title        = {Reinforced Continual Learning},
  author       = {Ju Xu and Zhanxing Zhu},
  year         = {2018},
  journal      = {NeurIPS},
  volume       = {31},
}

@article{Lesort2019,
  title        = {Continual Learning for Robotics: Definition, Framework, Learning Strategies, Opportunities and Challenges},
  author       = {Timothée Lesort and Vincenzo Lomonaco and Andrei Stoian and Davide Maltoni and David Filliat and Natalia Díaz-Rodríguez},
  year         = {2019},
  journal      = {Information Fusion},
  volume       = {58},
  pages        = {52--68},
}

@article{Ribeiro2019,
  title        = {Multi-task Learning and Catastrophic Forgetting in Continual Reinforcement Learning},
  author       = {João Ribeiro and Francisco S. Melo and João Dias},
  year         = {2019},
  journal      = {arXiv:1909.10008},
}

@article{Lo2019,
  title        = {Overcoming Catastrophic Interference in Online Reinforcement Learning with Dynamic Self-Organizing Maps},
  author       = {Yat Long Lo and Sina Ghiassian},
  year         = {2019},
  journal      = {arXiv:1910.13213},
}

@inproceedings{Abdolmaleki2020,
  title        = {A Distributional View on Multi-Objective Policy Optimization},
  author       = {Abbas Abdolmaleki and Sandy H. Huang and Leonard Hasenclever and Michael Neunert and H. Francis Song and Martina Zambelli and Murilo F. Martins and Nicolas Heess and Raia Hadsell and Martin Riedmiller},
  year         = {2020},
  booktitle    = {International Conference on Machine Learning},
  pages        = {11--22},
  organization = {PMLR},
}

@article{Xu2020,
  title        = {Task-Agnostic Online Reinforcement Learning with an Infinite Mixture of Gaussian Processes},
  author       = {Mengdi Xu and Wenhao Ding and Jiacheng Zhu and Zuxin Liu and Baiming Chen and Ding Zhao},
  year         = {2020},
  journal      = {Advances in Neural Information Processing Systems},
  volume       = {33},
  pages        = {6429--6440},
}

@inproceedings{Xu2020a,
  title        = {Knowledge Transfer in Multi-Task Deep Reinforcement Learning for Continuous Control},
  author       = {Zhiyuan Xu and Kun Wu and Zhengping Che and Jian Tang and Jieping Ye},
  year         = {2020},
  booktitle      = {NeurIPS},
  volume       = {33},
  pages        = {15146--15155},
}

@inproceedings{Pinto2020,
  title        = {Fast Reinforcement Learning with Incremental Gaussian Mixture Models},
  author       = {Rafael Pinto},
  year         = {2020},
  booktitle    = {International Joint Conference on Neural Networks (IJCNN)},
  pages        = {1--8},
  organization = {IEEE}
}

@article{Khetarpal2020,
  title        = {Towards Continual Reinforcement Learning: A Review and Perspectives},
  author       = {Khimya Khetarpal and Matthew Riemer and Irina Rish and Doina Precup},
  year         = {2020},
  journal      = { arXiv:2012.13490},
}

@inproceedings{Lan2021,
  title        = {Metrics and continuity in reinforcement learning},
  author       = {Charline Le Lan and Marc G. Bellemare and Pablo Samuel Castro},
  year         = {2021},
  booktitle    = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume       = {35},
  number       = {9},
  pages        = {8261--8269},
}

@inproceedings{CalvoFullana2021,
  title        = {Towards Safe Continuing Task Reinforcement Learning},
  author       = {Miguel Calvo-Fullana and Luiz F. O. Chamon and Santiago Paternain},
  year         = {2021},
  booktitle    = {2021 American Control Conference (ACC)},
  pages        = {902--908},
  organization = {IEEE}
}

@article{Kalashnikov2021,
  title        = {MT-Opt: Continuous Multi-Task Robotic Reinforcement Learning at Scale},
  author       = {Dmitry Kalashnikov and Jacob Varley and Yevgen Chebotar and Benjamin Swanson and Rico Jonschkowski and Chelsea Finn and Sergey Levine and Karol Hausman},
  year         = {2021},
  journal      = {arXiv:2104.08212},
}

@inproceedings{Wolczyk2021,
  title        = {Continual world: A robotic benchmark for continual reinforcement learning},
  author       = {Wo{\l}czyk, Maciej and Zajac, Micha{\l} and Pascanu, Razvan and Kucinski, Lukasz and Mi{\l}o{\'s}, Piotr},
  year         = {2021},
  booktitle    = {Advances in Neural Information Processing Systems},
  volume       = {34},
}

@inproceedings{Kessler2021,
  title        = {Same State, Different Task: Continual Reinforcement Learning without Interference},
  author       = {Samuel Kessler and Jack Parker-Holder and Philip Ball and Stefan Zohren and Stephen J. Roberts},
  year         = {2021},
  booktitle    = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume       = {36},
  number       = {7},
  pages        = {7143--7151},
}

@article{Powers2021,
  title        = {{CORA}: Benchmarks, Baselines, and Metrics as a Platform for Continual Reinforcement Learning Agents},
  author       = {Sam Powers and Eliot Xing and Eric Kolve and Roozbeh Mottaghi and Abhinav Gupta},
  year         = {2021},
  journal      = {arXiv:2110.10067},
}

@inproceedings{Kessler2020,
  title        = {{UNCLEAR}: A Straightforward Method for Continual Reinforcement Learning},
  author       = {Kessler, Samuel and Parker-Holder, Jack and Ball, Philip and Zohren, Stefan and Roberts, Stephen J},
  year         = {2020},
  booktitle    = {Proceedings of the International Conference on Machine Learning},
  volume       = {37},
}

@inproceedings{Camoriano2017,
  title        = {Incremental robot learning of new objects with fixed update time},
  author       = {Raffaello Camoriano and Giulia Pasquale and Carlo Ciliberto and Lorenzo Natale and Lorenzo Rosasco and Giorgio Metta},
  year         = {2017},
  booktitle    = {IEEE International Conference on Robotics and Automation (ICRA)},
  pages        = {3207--3214},
  organization = {IEEE}
}

@article{Wang2016,
  title        = {Learning to reinforcement learn},
  author       = {Jane X Wang and Zeb Kurth-Nelson and Dhruva Tirumala and Hubert Soyer and Joel Z Leibo and Remi Munos and Charles Blundell and Dharshan Kumaran and Matt Botvinick},
  year         = {2016},
  journal      = { arXiv:1611.05763},
}

@article{Kaplanis2019,
  title        = {Policy Consolidation for Continual Reinforcement Learning},
  author       = {Christos Kaplanis and Murray Shanahan and Claudia Clopath},
  year         = {2019},
  journal      = {arXiv:1902.00255},
}

@article{Traore2019,
  title        = {{DisCoRL}: Continual Reinforcement Learning via Policy Distillation},
  author       = {René Traoré and Hugo Caselles-Dupré and Timothée Lesort and Te Sun and Guanghang Cai and Natalia Díaz-Rodríguez and David Filliat},
  year         = {2019},
  journal      = {arXiv:1907.05855},
}

@article{Zhang2020,
  title        = {Task-agnostic Exploration in Reinforcement Learning},
  author       = {Xuezhou Zhang and Yuzhe ma and Adish Singla},
  year         = {2020},
  journal      = {Advances in Neural Information Processing Systems},
  volume       = {33},
  pages        = {11734--11743},
}

@article{Rammohan2021,
  title        = {Value-Based Reinforcement Learning for Continuous Control Robotic Manipulation in Multi-Task Sparse Reward Settings},
  author       = {Sreehari Rammohan and Shangqun Yu and Bowen He and Eric Hsiung and Eric Rosen and Stefanie Tellex and George Konidaris},
  year         = {2021},
  journal      = { arXiv:2107.13356},
}

@article{Khetarpal2018,
  title        = {Environments for Lifelong Reinforcement Learning},
  author       = {Khimya Khetarpal and Shagun Sodhani and Sarath Chandar and Doina Precup},
  year         = {2018},
  journal      = { arXiv:1811.10732},
}

@inproceedings{Yu2019,
  title        = {Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning},
  author       = {Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  year         = {2020},
  booktitle    = {Conference on Robot Learning},
  pages        = {1094--1100},
  organization = {PMLR},
}

@article{Mohammed2020,
  title        = {Can Reinforcement Learning for Continuous Control Generalize Across Physics Engines?},
  author       = {Aaqib Parvez Mohammed and Matias Valdenegro-Toro},
  year         = {2020},
  journal      = { arXiv:2010.14444},
}

@inproceedings{Hessel2017,
  title        = {Rainbow: Combining Improvements in Deep Reinforcement Learning},
  author       = {Matteo Hessel and Joseph Modayil and Hado van Hasselt and Tom Schaul and Georg Ostrovski and Will Dabney and Dan Horgan and Bilal Piot and Mohammad Azar and David Silver},
  year         = {2017},
  booktitle    = {AAAI conference on artificial intelligence},
  volume       = {32}
}

@article{Mankowitz2018,
  title        = {Unicorn: Continual Learning with a Universal, Off-policy Agent},
  author       = {Daniel J. Mankowitz and Augustin Žídek and André Barreto and Dan Horgan and Matteo Hessel and John Quan and Junhyuk Oh and Hado van Hasselt and David Silver and Tom Schaul},
  year         = {2018},
  journal      = { arXiv:1802.08294},
}

@inproceedings{Liu2021a,
  title        = {Learning without Knowing: Unobserved Context in Continuous Transfer Reinforcement Learning},
  author       = {Chenyu Liu and Yan Zhang and Yi Shen and Michael M. Zavlanos},
  year         = {2021},
  booktitle    = {Learning for Dynamics and Control},
  pages        = {791--802},
  organization = {PMLR}
}

@article{Roscow2021,
  title        = {Learning offline: memory replay in biological and artificial reinforcement learning},
  author       = {Emma L. Roscow and Raymond Chua and Rui Ponte Costa and Matt W. Jones and Nathan Lepora},
  year         = {2021},
  journal      = {Trends in neurosciences},
  volume       = {44},
  number       = {10},
  pages        = {808--821},
  publisher    = {Elsevier}
}

@article{Hu2021,
  title        = {Generalizable Episodic Memory for Deep Reinforcement Learning},
  author       = {Hao Hu and Jianing Ye and Guangxiang Zhu and Zhizhou Ren and Chongjie Zhang},
  year         = {2021},
  journal      = { arXiv:2103.06469},
}

@article{Raghavan2019,
  title        = {Generative Memory for Lifelong Reinforcement Learning},
  author       = {Aswin Raghavan and Jesse Hostetler and Sek Chai},
  year         = {2019},
  journal      = { arXiv:1902.08349},
}

@article{Xie2020,
  title        = {Deep Reinforcement Learning amidst Lifelong Non-Stationarity},
  author       = {Annie Xie and James Harrison and Chelsea Finn},
  year         = {2020},
  journal      = {arXiv:2006.10701},
}

@article{Li2020a,
  title        = {Some Insights into Lifelong Reinforcement Learning Systems},
  author       = {Changjian Li},
  year         = {2020},
  journal      = { arXiv:2001.09608},
}

@article{Team2021,
  title        = {Open-Ended Learning Leads to Generally Capable Agents},
  author       = {Open Ended Learning Team and Adam Stooke and Anuj Mahajan and Catarina Barros and Charlie Deck and Jakob Bauer and Jakub Sygnowski and Maja Trebacz and Max Jaderberg and Michael Mathieu and Nat McAleese and Nathalie Bradley-Schmieg and Nathaniel Wong and Nicolas Porcel and Roberta Raileanu and Steph Hughes-Fitt and Valentin Dalibard and Wojciech Marian Czarnecki},
  year         = {2021},
  journal      = { arXiv:2107.12808},
}

@inproceedings{Rolnick2019,
  title        = {Experience replay for continual learning},
  author       = {Rolnick, David and Ahuja, Arun and Schwarz, Jonathan and Lillicrap, Timothy and Wayne, Gregory},
  year         = {2019},
  booktitle      = {NeurIPS},
  volume       = {32},
}

@article{Li2021,
  title        = {Revisiting Prioritized Experience Replay: A Value Perspective},
  author       = {Ang A. Li and Zongqing Lu and Chenglin Miao},
  year         = {2021},
  journal      = { arXiv:2102.03261},
}

@inproceedings{Lomonaco2021,
  title        = {Avalanche: an end-to-end library for continual learning},
  author       = {Lomonaco, Vincenzo and Pellegrini, Lorenzo and Cossu, Andrea and Carta, Antonio and Graffieti, Gabriele and Hayes, Tyler L and De Lange, Matthias and Masana, Marc and Pomponi, Jary and Van de Ven, Gido M and others},
  year         = {2021},
  booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages        = {3600--3610},
}

@inproceedings{Lucchesi2022,
  title        = {Avalanche RL: A Continual Reinforcement Learning Library},
  author       = {Lucchesi, Nicol{\'o} and Carta, Antonio and Lomonaco, Vincenzo and Bacciu, Davide},
  year         = {2022},
  booktitle    = {Int. Conf. on Image Analysis and Processing},
  pages        = {524--535},
  organization = {Springer},
}

@article{Normandin2021,
  title        = {Sequoia: A Software Framework to Unify Continual Learning Research},
  author       = {Normandin, Fabrice and Golemo, Florian and Ostapenko, Oleksiy and Rodriguez, Pau and Riemer, Matthew D and Hurtado, Julio and Khetarpal, Khimya and Zhao, Dominic and Lindeborg, Ryan and Lesort, Timoth{\'e}e and others},
  year         = {2021},
  journal      = { arXiv:2108.01005},
}


@article{Thrun1995,
  title        = {Lifelong robot learning},
  author       = {Thrun, Sebastian and Mitchell, Tom M},
  year         = {1995},
  journal      = {Robotics and autonomous systems},
  volume       = {15},
  number       = {1-2},
  pages        = {25--46},
  publisher    = {Elsevier},
}

@article{Schaul2015,
  title        = {Prioritized experience replay},
  author       = {Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  year         = {2015},
  journal      = {arXiv:1511.05952},
}

@inproceedings{Andrychowicz2017,
  title        = {Hindsight experience replay},
  author       = {Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Pieter Abbeel, OpenAI and Zaremba, Wojciech},
  year         = {2017},
  booktitle      = {NeurIPS},
  volume       = {30},
}


@inproceedings{Novati2019,
  title        = {Remember and forget for experience replay},
  author       = {Novati, Guido and Koumoutsakos, Petros},
  year         = {2019},
  booktitle    = {{ICML}},
  pages        = {4851--4860},
}

@article{Zhang2017,
  title        = {A deeper look at experience replay},
  author       = {Zhang, Shangtong and Sutton, Richard S},
  year         = {2017},
  journal      = { arXiv:1712.01275},
}

@inproceedings{Fedus2020,
  title        = {Revisiting fundamentals of experience replay},
  author       = {Fedus, William and Ramachandran, Prajit and Agarwal, Rishabh and Bengio, Yoshua and Larochelle, Hugo and Rowland, Mark and Dabney, Will},
  year         = {2020},
  booktitle    = {{ICML}},
  pages        = {3061--3071},
}

@article{Cassirer2021,
  title        = {Reverb: A framework for experience replay},
  author       = {Cassirer, Albin and Barth-Maron, Gabriel and Brevdo, Eugene and Ramos, Sabela and Boyd, Toby and Sottiaux, Thibault and Kroiss, Manuel},
  year         = {2021},
  journal      = {arXiv:2102.04736},
}

@inproceedings{Ammar2014,
  title        = {Online multi-task learning for policy gradient methods},
  author       = {Ammar, Haitham Bou and Eaton, Eric and Ruvolo, Paul and Taylor, Matthew},
  year         = {2014},
  booktitle    = {{ICML}},
  pages        = {1206--1214},
}

@article{Teh2017,
  title        = {Distral: Robust multitask reinforcement learning},
  author       = {Teh, Yee and Bapst, Victor and Czarnecki, Wojciech M and Quan, John and Kirkpatrick, James and Hadsell, Raia and Heess, Nicolas and Pascanu, Razvan},
  year         = {2017},
  journal      = {Advances in Neural Information Processing Systems},
  volume       = {30},
}

@article{Plappert2018,
  title        = {Multi-goal reinforcement learning: Challenging robotics environments and request for research},
  author       = {Plappert, Matthias and Andrychowicz, Marcin and Ray, Alex and McGrew, Bob and Baker, Bowen and Powell, Glenn and Schneider, Jonas and Tobin, Josh and Chociej, Maciek and Welinder, Peter and others},
  year         = {2018},
  journal      = {arXiv:1802.09464},
}

@article{Sorokin2019,
  title        = {Continual and multi-task reinforcement learning with shared episodic memory},
  author       = {Sorokin, Artyom Y and Burtsev, Mikhail S},
  year         = {2019},
  journal      = {arXiv:1905.02662},
}

@inproceedings{Zhao2019,
  title        = {Maximum entropy-regularized multi-goal reinforcement learning},
  author       = {Zhao, Rui and Sun, Xudong and Tresp, Volker},
  year         = {2019},
  booktitle    = {{ICML}},
  pages        = {7553--7562},
  }

@inproceedings{Bram2019,
  title        = {Attentive multi-task deep reinforcement learning},
  author       = {Br{\"a}m, Timo and Brunner, Gino and Richter, Oliver and Wattenhofer, Roger},
  year         = {2019},
  booktitle    = {Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages        = {134--149},
  organization = {Springer}
}

@article{Landolfi2019,
  title        = {A model-based approach for sample-efficient multi-task reinforcement learning},
  author       = {Landolfi, Nicholas C and Thomas, Garrett and Ma, Tengyu},
  year         = {2019},
  journal      = {arXiv:1907.04964},
}

@article{Li2020b,
  title        = {Multi-task batch reinforcement learning with metric learning},
  author       = {Li, Jiachen and Vuong, Quan and Liu, Shuang and Liu, Minghua and Ciosek, Kamil and Christensen, Henrik and Su, Hao},
  year         = {2020},
  journal      = {Advances in Neural Information Processing Systems},
  volume       = {33},
  pages        = {6197--6210},
}

@article{Garcia2020,
  title        = {Learning Reusable Options for Multi-Task Reinforcement Learning},
  author       = {Garcia, Francisco M and Nota, Chris and Thomas, Philip S},
  year         = {2020},
  journal      = {arXiv:2001.01577},
}

@inproceedings{Yang2020,
  title        = {Multi-task reinforcement learning with soft modularization},
  author       = {Yang, Ruihan and Xu, Huazhe and Wu, Yi and Wang, Xiaolong},
  year         = {2020},
  booktitle      = {NeurIPS},
  volume       = {33},
  pages        = {4767--4777},
}

@inproceedings{Zeng2021,
  title        = {A decentralized policy gradient approach to multi-task reinforcement learning},
  author       = {Zeng, Sihan and Anwar, Malik Aqeel and Doan, Thinh T and Raychowdhury, Arijit and Romberg, Justin},
  year         = {2021},
  booktitle    = {Uncertainty in Artificial Intelligence},
  pages        = {1002--1012},
  organization = {PMLR},
}

@article{Cervino2021,
  title        = {Multi-task reinforcement learning in reproducing kernel hilbert spaces via cross-learning},
  author       = {Cervino, Juan and Bazerque, Juan Andr{\'e}s and Calvo-Fullana, Miguel and Ribeiro, Alejandro},
  year         = {2021},
  journal      = {IEEE Transactions on Signal Processing},
  volume       = {69},
  pages        = {5947--5962},
  publisher    = {IEEE},
}

@inproceedings{Sodhani2021,
  title        = {Multi-task reinforcement learning with context-based representations},
  author       = {Sodhani, Shagun and Zhang, Amy and Pineau, Joelle},
  year         = {2021},
  booktitle    = {International Conference on Machine Learning},
  pages        = {9767--9779},
  organization = {PMLR},
}

@inproceedings{Gupta2021,
  title        = {Reset-free reinforcement learning via multi-task learning: Learning dexterous manipulation behaviors without human intervention},
  author       = {Gupta, Abhishek and Yu, Justin and Zhao, Tony Z and Kumar, Vikash and Rovinsky, Aaron and Xu, Kelvin and Devlin, Thomas and Levine, Sergey},
  booktitle    = {{ICRA}},
  pages        = {6664--6671},
  year         = {2021},
  organization = {IEEE},
}

@article{Blier2021,
  title        = {Unbiased Methods for Multi-Goal Reinforcement Learning},
  author       = {Blier, L{\'e}onard and Ollivier, Yann},
  year         = {2021},
  journal      = {arXiv:2106.08863},
}

@article{Kelly2021,
  title        = {Evolving hierarchical memory-prediction machines in multi-task reinforcement learning},
  author       = {Kelly, Stephen and Voegerl, Tatiana and Banzhaf, Wolfgang and Gondro, Cedric},
  year         = {2021},
  journal      = {Genetic Programming and Evolvable Machines},
  volume       = {22},
  number       = {4},
  pages        = {573--605},
  publisher    = {Springer}
}

@article{Zhang2021,
  title        = {Provably efficient multi-task reinforcement learning with model transfer},
  author       = {Zhang, Chicheng and Wang, Zhi},
  year         = {2021},
  journal      = {Advances in Neural Information Processing Systems},
  volume       = {34},
}

@article{Kim2021,
  title        = {Goal-Aware Cross-Entropy for Multi-Target Reinforcement Learning},
  author       = {Kim, Kibeom and Lee, Min Whoo and Kim, Yoonsung and Ryu, JeHwan and Lee, Minsu and Zhang, Byoung-Tak},
  year         = {2021},
  journal      = {Advances in Neural Information Processing Systems},
  volume       = {34},
}

@inproceedings{Schiewer2021,
  title        = {Modular Networks Prevent Catastrophic Interference in Model-Based Multi-Task Reinforcement Learning},
  author       = {Schiewer, Robin and Wiskott, Laurenz},
  year         = {2021},
  booktitle    = {Int. Conf. on Machine Learning, Optimization, and Data Science},
  pages        = {299--313},
  organization = {Springer},
}

@inproceedings{Brunskill2014,
  title        = {Pac-inspired option discovery in lifelong reinforcement learning},
  author       = {Brunskill, Emma and Li, Lihong},
  year         = {2014},
  booktitle    = {International conference on machine learning},
  pages        = {316--324},
  organization = {PMLR},
}

@article{Rusu2015,
  title        = {Policy distillation},
  author       = {Rusu, Andrei A and Colmenarejo, Sergio Gomez and Gulcehre, Caglar and Desjardins, Guillaume and Kirkpatrick, James and Pascanu, Razvan and Mnih, Volodymyr and Kavukcuoglu, Koray and Hadsell, Raia},
  year         = {2015},
  journal      = {arXiv:1511.06295},
}

@article{Jaderberg2016,
  title        = {Reinforcement learning with unsupervised auxiliary tasks},
  author       = {Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray},
  year         = {2016},
  journal      = {arXiv:1611.05397},
}

@inproceedings{Tessler2017,
  title        = {A deep hierarchical approach to lifelong learning in minecraft},
  author       = {Tessler, Chen and Givony, Shahar and Zahavy, Tom and Mankowitz, Daniel and Mannor, Shie},
  year         = {2017},
  booktitle    = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume       = {31},
  number       = {1},
}

@article{Erickson2017,
  title        = {Dex: Incremental Learning for Complex Environments in Deep Reinforcement Learning},
  author       = {Erickson, Nick and Zhao, Qi},
  year         = {2017},
  journal      = { arXiv:1706.05749},
}

@inproceedings{Kaplanis2018,
  title        = {Continual reinforcement learning with complex synapses},
  author       = {Kaplanis, Christos and Shanahan, Murray and Clopath, Claudia},
  year         = {2018},
  booktitle    = {{ICML}},
  pages        = {2497--2506},
}

@article{Nagabandi2018,
  title        = {Learning to adapt in dynamic, real-world environments through meta-reinforcement learning},
  author       = {Nagabandi, Anusha and Clavera, Ignasi and Liu, Simin and Fearing, Ronald S and Abbeel, Pieter and Levine, Sergey and Finn, Chelsea},
  year         = {2018},
  journal      = { arXiv:1803.11347},
}

@article{Nagabandi2018a,
  title        = {Deep online learning via meta-learning: Continual adaptation for model-based RL},
  author       = {Nagabandi, Anusha and Finn, Chelsea and Levine, Sergey},
  year         = {2018},
  journal      = { arXiv:1812.07671},
}

@article{Caselles2018,
  title        = {Continual state representation learning for reinforcement learning using generative replay},
  year         = {2018},
  author       = {Caselles-Dupr{\'e}, Hugo and Garcia-Ortiz, Michael and Filliat, David},
  journal      = { arXiv:1810.03880},
}

@article{George2019,
  title        = {Self-organizing maps for storage and transfer of knowledge in reinforcement learning},
  author       = {George Karimpanal, Thommen and Bouffanais, Roland},
  year         = {2019},
  journal      = {Adaptive Behavior},
  volume       = {27},
  number       = {2},
  pages        = {111--126},
  publisher    = {SAGE Publications Sage UK: London, England},
}

@article{Atkinson2021,
  title        = {Pseudo-rehearsal: Achieving deep reinforcement learning without catastrophic forgetting},
  author       = {Atkinson, Craig and McCane, Brendan and Szymanski, Lech and Robins, Anthony},
  year         = {2021},
  journal      = {Neurocomputing},
  volume       = {428},
  pages        = {291--307},
  publisher    = {Elsevier},
}

@article{Wu2020,
  title        = {Model primitives for hierarchical lifelong reinforcement learning},
  author       = {Wu, Bohan and Gupta, Jayesh K and Kochenderfer, Mykel},
  year         = {2020},
  journal      = {Autonomous Agents and Multi-Agent Systems},
  volume       = {34},
  number       = {1},
  pages        = {1--38},
  publisher    = {Springer},
}

@article{Ketz2019,
  title        = {Continual Learning Using World Models for Pseudo-Rehearsal},
  author       = {Ketz, Nicholas and Kolouri, Soheil and Pilly, Praveen},
  year         = {2019},
  journal      = { arXiv:1903.02647},
}

@inproceedings{Kalifou2019,
  title        = {Continual reinforcement learning deployed in real-life using policy distillation and sim2real transfer},
  author       = {Kalifou, Ren{\'e} Traor{\'e} and Caselles-Dupr{\'e}, Hugo and Lesort, Timoth{\'e}e and Sun, Te and Diaz-Rodriguez, Natalia and Filliat, David},
  year         = {2019},
  booktitle    = {ICML Workshop on Multi-Task and Lifelong Learning},
  volume       = {4},
}

@article{Mufti2019,
  title        = {Iterative model-based reinforcement learning using simulations in the differentiable neural computer},
  author       = {Mufti, Adeel and Penkov, Svetlin and Ramamoorthy, Subramanian},
  year         = {2019},
  journal      = { arXiv:1906.07248},
}

@article{Kaplanis2020,
  title        = {Continual reinforcement learning with multi-timescale replay},
  author       = {Kaplanis, Christos and Clopath, Claudia and Shanahan, Murray},
  year         = {2020},
  journal      = { arXiv:2004.07530},
}

@article{Julian2020,
  title        = {Never stop learning: The effectiveness of fine-tuning in robotic reinforcement learning},
  year         = {2020},
  author       = {Julian, Ryan and Swanson, Benjamin and Sukhatme, Gaurav S and Levine, Sergey and Finn, Chelsea and Hausman, Karol},
  journal      = { arXiv:2004.10190},
}

@article{Padakandla2021,
  title        = {A survey of reinforcement learning algorithms for dynamically varying environments},
  author       = {Padakandla, Sindhu},
  year         = {2021},
  journal      = {ACM Computing Surveys (CSUR)},
  volume       = {54},
  number       = {6},
  pages        = {1--25},
  publisher    = {ACM New York, NY, USA},
}

@article{Wang2021,
  title        = {Lifelong Incremental Reinforcement Learning With Online Bayesian Inference},
  author       = {Wang, Zhi and Chen, Chunlin and Dong, Daoyi},
  year         = {2021},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  publisher    = {IEEE},
}

@article{Zhu2020a,
  title        = {Transfer learning in deep reinforcement learning: A survey},
  author       = {Zhu, Zhuangdi and Lin, Kaixiang and Zhou, Jiayu},
  year         = {2020},
  journal      = { arXiv:2009.07888},
}

@article{Struye2020,
  title        = {HTMRL: Biologically Plausible Reinforcement Learning with Hierarchical Temporal Memory},
  author       = {Struye, Jakob and Mets, Kevin and Latr{\'e}, Steven},
  year         = {2020},
  journal      = { arXiv:2009.08880},
}

@inproceedings{Huang2021,
  title        = {Continual model-based reinforcement learning with hypernetworks},
  author       = {Huang, Yizhou and Xie, Kevin and Bharadhwaj, Homanga and Shkurti, Florian},
  year         = {2021},
  booktitle    = {{ICRA}},
  pages        = {799--805},
  organization = {IEEE},
}

@inproceedings{Jiang2021,
  title        = {Prioritized level replay},
  author       = {Jiang, Minqi and Grefenstette, Edward and Rockt{\"a}schel, Tim},
  year         = {2021},
  booktitle    = {International Conference on Machine Learning},
  pages        = {4940--4950},
  organization = {PMLR},
}

@article{Wang2022,
  title        = {Instance weighted incremental evolution strategies for reinforcement learning in dynamic environments},
  author       = {Wang, Zhi and Chen, Chunlin and Dong, Daoyi},
  year         = {2022},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  publisher    = {IEEE},
}

@article{Lu2020,
  title        = {Reset-free lifelong learning with skill-space planning},
  author       = {Lu, Kevin and Grover, Aditya and Abbeel, Pieter and Mordatch, Igor},
  year         = {2020},
  journal      = { arXiv:2012.03548},
}

@inproceedings{Filos2021,
  title        = {Psiphi-learning: Reinforcement learning with demonstrations using successor features and inverse temporal difference learning},
  author       = {Filos, Angelos and Lyle, Clare and Gal, Yarin and Levine, Sergey and Jaques, Natasha and Farquhar, Gregory},
  year         = {2021},
  booktitle    = {International Conference on Machine Learning},
  pages        = {3305--3317},
  organization = {PMLR},
}

@inproceedings{Nekoei2021,
  title        = {Continuous coordination as a realistic scenario for lifelong learning},
  author       = {Nekoei, Hadi and Badrinaaraayanan, Akilesh and Courville, Aaron and Chandar, Sarath},
  year         = {2021},
  booktitle    = {International Conference on Machine Learning},
  pages        = {8016--8024},
  organization = {PMLR},
}

@inproceedings{Hafez2021,
  title        = {Behavior Self-Organization Supports Task Inference for Continual Robot Learning},
  author       = {Hafez, Muhammad Burhan and Wermter, Stefan},
  year         = {2021},
  booktitle    = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages        = {6739--6746},
  organization = {IEEE},
}

@article{Zhang2022,
  title        = {Catastrophic Interference in Reinforcement Learning: A Solution Based on Context Division and Knowledge Distillation},
  author       = {Zhang, Tiantian and Wang, Xueqian and Liang, Bin and Yuan, Bo},
  year         = {2022},
  journal      = {IEEE Trans. on Neural Networks and Learning Systems},
  publisher    = {IEEE},
}

@article{Johnson2022,
  title        = {L2Explorer: A Lifelong Reinforcement Learning Assessment Environment},
  author       = {Johnson, Erik C and Nguyen, Eric Q and Schreurs, Blake and Ewulum, Chigozie S and Ashcraft, Chace and Fendley, Neil M and Baker, Megan M and New, Alexander and Vallabha, Gautam K},
  year         = {2022},
  journal      = {arXiv:2203.07454},
}

@article{Caccia2022,
  title        = {Task-Agnostic Continual Reinforcement Learning: In Praise of a Simple Baseline},
  author       = {Caccia, Massimo and Mueller, Jonas and Kim, Taesup and Charlin, Laurent and Fakoor, Rasool},
  year         = {2022},
  journal      = { arXiv:2205.14495},
}

@inproceedings{Mendez2021,
  title        = {Modular Lifelong Reinforcement Learning via Neural Composition},
  author       = {Mendez, Jorge A and van Seijen, Harm and Eaton, Eric},
  year         = {2021},
  booktitle    = {{ICLR}},
}

@inproceedings{Bagus2022,
  title        = {A Study of Continual Learning Methods for {Q}-Learning},
  author       = {Bagus, Benedikt and Gepperth, Alexander},
  year         = {2022},
  booktitle    = {{IJCNN}},
}

@article{Kirk2021,
  title        = {A survey of generalisation in deep reinforcement learning},
  author       = {Kirk, Robert and Zhang, Amy and Grefenstette, Edward and Rockt{\"a}schel, Tim},
  year         = {2021},
  journal      = { arXiv:2111.09794},
}

@article{Zhu2020b,
  title        = {The ingredients of real-world robotic reinforcement learning},
  author       = {Zhu, Henry and Yu, Justin and Gupta, Abhishek and Shah, Dhruv and Hartikainen, Kristian and Singh, Avi and Kumar, Vikash and Levine, Sergey},
  year         = {2020},
  journal      = { arXiv:2004.12570},
}

@article{Narvekar2020,
  title        = {Curriculum learning for reinforcement learning domains: A framework and survey},
  author       = {Narvekar, Sanmit and Peng, Bei and Leonetti, Matteo and Sinapov, Jivko and Taylor, Matthew E and Stone, Peter},
  year         = {2020},
  journal      = { arXiv:2003.04960},
}

@article{Denoyer2021,
  title        = {SaLinA: Sequential Learning of Agents},
  author       = {Denoyer, Ludovic and de la Fuente, Alfredo and Duong, Song and Gaya, Jean-Baptiste and Kamienny, Pierre-Alexandre and Thompson, Daniel H},
  year         = {2021},
  journal      = { arXiv:2110.07910},
}


@inproceedings{Mendez2020,
  title        = {Lifelong policy gradient learning of factored policies for faster training without forgetting},
  author       = {Mendez, Jorge and Wang, Boyu and Eaton, Eric},
  year         = {2020},
  booktitle      = {NeurIPS},
  volume       = {33},
  pages        = {14398--14409},
}

@Comment{jabref-meta: databaseType:bibtex;}
